**The report required for explaining the approach, preprocessing steps, pipeline architecture, and evaluation results, and the interpretation of the visualizations, has been uploaded in the 'Report' folder.**

## SHL Hiring Assessment (Audio Feature Extraction and Grammar Score Prediction)

```<pre><code>```markdown # ğŸ§ Audio Grammar Scoring This project aims to predict grammar scores from raw `.wav` audio files using various audio feature extraction techniques and machine learning models. ğŸ“ **The report explaining the approach, preprocessing steps, pipeline architecture, evaluation results, and visualization interpretation has been uploaded in the `Report` folder.** --- ## ğŸ“¦ Dataset Structure ``` dataset/ â”œâ”€â”€ audio_files/ â”‚ â”œâ”€â”€ audio_1.wav â”‚ â”œâ”€â”€ audio_2.wav â”‚ â””â”€â”€ ... â”œâ”€â”€ train.csv # Training data with filenames and grammar labels â”œâ”€â”€ test.csv # Test data with filenames and dummy labels â””â”€â”€ sample_submission.csv # Submission format ``` --- ## ğŸš€ Getting Started ### 1. Clone the Repository ```bash git clone https://github.com/your-username/audio-grammar-scoring.git cd audio-grammar-scoring ``` ### 2. Install Dependencies ```bash pip install -r requirements.txt ``` ### 3. Run the Main Script ```bash python main.py ``` --- ## ğŸ§  Approach 1. **Raw `.wav` Audio** - Input audio is in `.wav` format. 2. **Feature Extraction** - Extracted using `librosa`: - **MFCCs** - **Chroma Features** - **Spectral Contrast** - **Zero Crossing Rate (ZCR)** - **RMSE Energy** - **Spectral Rolloff** - **Tempo** 3. **Feature Matrix** - Features are combined into a numerical matrix. 4. **Standard Scaling** - Features are normalized using StandardScaler. 5. **Train/Test Split** - Dataset is split: 80% train, 20% test. 6. **Model Training** - Models used: - Random Forest (Balanced) - XGBoost - Gradient Boosting 7. **Evaluation** - Metrics: - Pearson Correlation Coefficient: `r = 0.648` - RÂ²: `0.395` - RMSE: `0.908` 8. **Grammar Score Prediction** - Predict scores from features using trained models. --- ## ğŸ” How It Works - Load data and audio files - Perform Exploratory Data Analysis (EDA) - Extract features using Librosa - Preprocess and normalize features - Train models (Random Forest, XGBoost) - Evaluate using Pearson correlation and error metrics --- ## ğŸ“Š Exploratory Data Analysis (EDA) ### 1. Grammar Score Distribution - Most common score: `5.0` - Rare scores: `1.0`, `1.5`, `2.0` - Right-skewed distribution ğŸ“Œ _Imbalance suggests need for class weighting or augmentation_ --- ### 2. Audio Duration - Most clips: `< 20 seconds` - Few outliers: `> 60 seconds` ğŸ“Œ _Long recordings may affect model learning_ --- ### 3. Sample Rate - All clips have a uniform rate: `16 kHz` ğŸ“Œ _Ideal for speech tasks; no resampling needed_ --- ## ğŸ¼ Feature Extraction (Librosa) | Feature | Description | |--------------------|-------------------------------------------------------------------------| | MFCCs | Capture timbral & phonetic patterns | | Chroma | Emphasize harmonic content | | Spectral Contrast | Detect voiced/unvoiced transitions & articulation quality | | ZCR | Measures noisiness/disfluencies via signal sign changes | | RMSE | Indicates speech energy; emotion or emphasis | | Spectral Rolloff | Captures sharp consonants or spectral spread | | Tempo | Estimates rhythm/fluency of speech | --- ## ğŸ“ˆ Feature-Label Insights ### ğŸ”¹ ZCR (Zero Crossing Rate) - Low scores â†’ High ZCR â†’ Noisy or disfluent speech - High scores â†’ Low ZCR â†’ Clear articulation ### ğŸ”¹ RMSE (Energy) - Low scores â†’ Variable RMSE â†’ Emotional or unstable tone - High scores â†’ Stable RMSE â†’ Smooth, controlled delivery ### ğŸ”¹ Spectral Rolloff - Low scores â†’ High rolloff â†’ Harsh articulation - High scores â†’ Low rolloff â†’ Balanced speech --- ## âš™ï¸ Modeling Pipeline ### ğŸ§ª Preprocessing - StandardScaler applied to features - 80/20 train-test split --- ### ğŸ§  Model Training & Results | Model | Pearson (r) | RÂ² Score | RMSE | MAE | MAPE | |-------------------------|-------------|----------|--------|--------|--------| | Random Forest (unbalanced) | 0.634 | 0.383 | 0.917 | ~0.75 | ~25% | | Random Forest (balanced) | **0.648** | **0.395**| **0.908** | ~0.75 | ~25% | | XGBoost | Lower performance | | | | | âœ… **Best Model**: Balanced Random Forest with GridSearchCV --- ## ğŸ“ Evaluation Metric ### ğŸ“Œ Pearson Correlation Coefficient (r) - Used as the **primary evaluation metric** - Measures correlation strength between predicted and true grammar scores --- ## ğŸ§° Requirements - Python 3.x - Libraries: - numpy - scikit-learn - xgboost - librosa - pandas - matplotlib --- ``` </code></pre> ```
