**The report required for explaining the approach, preprocessing steps, pipeline architecture, and evaluation results, and the interpretation of the visualizations, has been uploaded in the 'Report' folder.**

## SHL Hiring Assessment (Audio Feature Extraction and Grammar Score Prediction)

```<pre><code>```markdown # 🎧 Audio Grammar Scoring This project aims to predict grammar scores from raw `.wav` audio files using various audio feature extraction techniques and machine learning models. 📁 **The report explaining the approach, preprocessing steps, pipeline architecture, evaluation results, and visualization interpretation has been uploaded in the `Report` folder.** --- ## 📦 Dataset Structure ``` dataset/ ├── audio_files/ │ ├── audio_1.wav │ ├── audio_2.wav │ └── ... ├── train.csv # Training data with filenames and grammar labels ├── test.csv # Test data with filenames and dummy labels └── sample_submission.csv # Submission format ``` --- ## 🚀 Getting Started ### 1. Clone the Repository ```bash git clone https://github.com/your-username/audio-grammar-scoring.git cd audio-grammar-scoring ``` ### 2. Install Dependencies ```bash pip install -r requirements.txt ``` ### 3. Run the Main Script ```bash python main.py ``` --- ## 🧠 Approach 1. **Raw `.wav` Audio** - Input audio is in `.wav` format. 2. **Feature Extraction** - Extracted using `librosa`: - **MFCCs** - **Chroma Features** - **Spectral Contrast** - **Zero Crossing Rate (ZCR)** - **RMSE Energy** - **Spectral Rolloff** - **Tempo** 3. **Feature Matrix** - Features are combined into a numerical matrix. 4. **Standard Scaling** - Features are normalized using StandardScaler. 5. **Train/Test Split** - Dataset is split: 80% train, 20% test. 6. **Model Training** - Models used: - Random Forest (Balanced) - XGBoost - Gradient Boosting 7. **Evaluation** - Metrics: - Pearson Correlation Coefficient: `r = 0.648` - R²: `0.395` - RMSE: `0.908` 8. **Grammar Score Prediction** - Predict scores from features using trained models. --- ## 🔍 How It Works - Load data and audio files - Perform Exploratory Data Analysis (EDA) - Extract features using Librosa - Preprocess and normalize features - Train models (Random Forest, XGBoost) - Evaluate using Pearson correlation and error metrics --- ## 📊 Exploratory Data Analysis (EDA) ### 1. Grammar Score Distribution - Most common score: `5.0` - Rare scores: `1.0`, `1.5`, `2.0` - Right-skewed distribution 📌 _Imbalance suggests need for class weighting or augmentation_ --- ### 2. Audio Duration - Most clips: `< 20 seconds` - Few outliers: `> 60 seconds` 📌 _Long recordings may affect model learning_ --- ### 3. Sample Rate - All clips have a uniform rate: `16 kHz` 📌 _Ideal for speech tasks; no resampling needed_ --- ## 🎼 Feature Extraction (Librosa) | Feature | Description | |--------------------|-------------------------------------------------------------------------| | MFCCs | Capture timbral & phonetic patterns | | Chroma | Emphasize harmonic content | | Spectral Contrast | Detect voiced/unvoiced transitions & articulation quality | | ZCR | Measures noisiness/disfluencies via signal sign changes | | RMSE | Indicates speech energy; emotion or emphasis | | Spectral Rolloff | Captures sharp consonants or spectral spread | | Tempo | Estimates rhythm/fluency of speech | --- ## 📈 Feature-Label Insights ### 🔹 ZCR (Zero Crossing Rate) - Low scores → High ZCR → Noisy or disfluent speech - High scores → Low ZCR → Clear articulation ### 🔹 RMSE (Energy) - Low scores → Variable RMSE → Emotional or unstable tone - High scores → Stable RMSE → Smooth, controlled delivery ### 🔹 Spectral Rolloff - Low scores → High rolloff → Harsh articulation - High scores → Low rolloff → Balanced speech --- ## ⚙️ Modeling Pipeline ### 🧪 Preprocessing - StandardScaler applied to features - 80/20 train-test split --- ### 🧠 Model Training & Results | Model | Pearson (r) | R² Score | RMSE | MAE | MAPE | |-------------------------|-------------|----------|--------|--------|--------| | Random Forest (unbalanced) | 0.634 | 0.383 | 0.917 | ~0.75 | ~25% | | Random Forest (balanced) | **0.648** | **0.395**| **0.908** | ~0.75 | ~25% | | XGBoost | Lower performance | | | | | ✅ **Best Model**: Balanced Random Forest with GridSearchCV --- ## 📏 Evaluation Metric ### 📌 Pearson Correlation Coefficient (r) - Used as the **primary evaluation metric** - Measures correlation strength between predicted and true grammar scores --- ## 🧰 Requirements - Python 3.x - Libraries: - numpy - scikit-learn - xgboost - librosa - pandas - matplotlib --- ``` </code></pre> ```
